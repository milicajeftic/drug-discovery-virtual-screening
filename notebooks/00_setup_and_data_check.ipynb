{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267ce77c",
   "metadata": {},
   "source": [
    "# 00 – Setup and Data Check\n",
    "#\n",
    "# Project: Predictive Modeling for Drug Discovery via Virtual Screening\n",
    "# Student: Milica Jeftić (ID: 89211255)\n",
    "# Date: January 2026\n",
    "# Dataset: Kaggle – Drug Discovery Virtual Screening Dataset\n",
    "#\n",
    "# --------------------------------------------------------------------\n",
    "#\n",
    "# Goal of This Notebook\n",
    "#\n",
    "# This notebook initializes the environment, loads the raw dataset, and\n",
    "# performs basic data quality checks. The objectives are:\n",
    "#\n",
    "# 1. Environment Setup\n",
    "#    - Import required libraries and configure the analysis environment\n",
    "#\n",
    "# 2. Data Loading\n",
    "#    - Load the raw dataset from data/raw/\n",
    "#\n",
    "# 3. Initial Exploration\n",
    "#    - Inspect dataset shape, column names, and data types\n",
    "#\n",
    "# 4. Quality Assessment\n",
    "#    - Identify missing values, duplicate records, and potential anomalies\n",
    "#\n",
    "# 5. Target Analysis\n",
    "#    - Examine the distribution of activity labels\n",
    "#      (0 = inactive, 1 = active)\n",
    "#\n",
    "# NOTE:\n",
    "# No preprocessing or modeling is performed in this notebook.\n",
    "# The purpose is to establish a baseline understanding of the raw data.\n",
    "#\n",
    "# --------------------------------------------------------------------\n",
    "#\n",
    "# Expected Outputs\n",
    "#\n",
    "# - Data quality summary report (saved to results/metrics/)\n",
    "# - Basic descriptive statistics\n",
    "# - Target distribution visualization (saved to results/figures/)\n",
    "# - Notes on immediate data issues to address during preprocessing\n",
    "#\n",
    "# --------------------------------------------------------------------\n",
    "#\n",
    "# Dataset Reference\n",
    "#\n",
    "# Source: Kaggle – Drug Discovery Virtual Screening Dataset\n",
    "# Link: https://www.kaggle.com/datasets/shahriarkabir/drug-discovery-virtual-screening-dataset\n",
    "# Description:\n",
    "# Approximately 2,000 chemical compounds characterized by molecular\n",
    "# descriptors and a binary activity label indicating biological activity.\n",
    "#\n",
    "# --------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626419e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KORISNIK\\Documents\\drug-discovery-virtual-screening\\.conda\\python.exe\n",
      "3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960c2e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Environment initialized successfully\n",
      "============================================================\n",
      "Python       : 3.10.19\n",
      "Numpy        : 2.2.5\n",
      "Pandas       : 2.3.3\n",
      "Seaborn      : 0.13.2\n",
      "Matplotlib   : 3.10.8\n",
      "------------------------------------------------------------\n",
      "Project root : c:\\Users\\KORISNIK\\Documents\\drug-discovery-virtual-screening\n",
      "Raw data dir : c:\\Users\\KORISNIK\\Documents\\drug-discovery-virtual-screening\\data\\raw\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Environment & Configuration\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# ----------------------------\n",
    "# Warning configuration\n",
    "# ----------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# ----------------------------\n",
    "# Pandas display options\n",
    "# ----------------------------\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "\n",
    "# ----------------------------\n",
    "# Visualization defaults\n",
    "# ----------------------------\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "rcParams[\"figure.figsize\"] = (10, 6)\n",
    "rcParams[\"font.size\"] = 12\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# ----------------------------\n",
    "# Project paths\n",
    "# ----------------------------\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "DATA_RAW_PATH = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "DATA_PROCESSED_PATH = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "RESULTS_PATH = os.path.join(PROJECT_ROOT, \"results\")\n",
    "\n",
    "# ----------------------------\n",
    "# Environment summary\n",
    "# ----------------------------\n",
    "print(\"=\" * 60)\n",
    "print(\"Environment initialized successfully\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python       : {sys.version.split()[0]}\")\n",
    "print(f\"Numpy        : {np.__version__}\")\n",
    "print(f\"Pandas       : {pd.__version__}\")\n",
    "print(f\"Seaborn      : {sns.__version__}\")\n",
    "print(f\"Matplotlib   : {plt.matplotlib.__version__}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Project root : {PROJECT_ROOT}\")\n",
    "print(f\"Raw data dir : {DATA_RAW_PATH}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0bf68b",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Now that the environment is set up, we load the raw dataset containing chemical compound properties\n",
    "and their activity labels. This dataset serves as the foundation for all subsequent exploratory\n",
    "analysis and preprocessing steps.\n",
    "\n",
    "**Expected dataset characteristics:**\n",
    "- Approximately 2,000 chemical compounds\n",
    "- Multiple molecular descriptors (numerical features)\n",
    "- Binary activity label: 0 = inactive, 1 = active (this is our target variable)\n",
    "- Format: CSV file located at `data/raw/drug_discovery_virtual_screening.csv`\n",
    "\n",
    "We will load the dataset and perform initial checks to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee47b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading dataset...\n",
      "============================================================\n",
      "✓ Dataset loaded successfully from: c:\\Users\\KORISNIK\\Documents\\drug-discovery-virtual-screening\\data\\raw\\drug_discovery_virtual_screening.csv\n",
      "\n",
      "Dataset shape: 2000 rows × 17 columns\n",
      "\n",
      "First 5 rows:\n",
      "  compound_id protein_id  molecular_weight   logp  h_bond_donors  h_bond_acceptors  rotatable_bonds  \\\n",
      "0   CID_00000    PID_361          499.6714 2.4872              1                 7                4   \n",
      "1   CID_00001    PID_165          436.1736 3.2832              3                 4                4   \n",
      "2   CID_00002    PID_168          514.7689    NaN              2                11               11   \n",
      "3   CID_00003    PID_226          602.3030 3.0381              0                 5                5   \n",
      "4   CID_00004    PID_224          426.5847 0.6596              2                 4                5   \n",
      "\n",
      "   polar_surface_area  compound_clogp  protein_length  protein_pi  hydrophobicity  binding_site_size  mw_ratio  \\\n",
      "0            113.3508          4.0507             678      6.0197          0.8125            12.5122    0.7370   \n",
      "1             71.9811          3.7044             876      6.4474          0.6514            11.5384    0.4979   \n",
      "2             83.9363          1.8696             658      3.9258          0.6335            13.1557    0.7823   \n",
      "3             79.8681          2.4519             312      7.5971          0.5130            12.0718    1.9305   \n",
      "4             88.1987          1.7719            1418      4.2495          0.6136            15.8504    0.3008   \n",
      "\n",
      "   logp_pi_interaction  binding_affinity  active  \n",
      "0              14.9723            5.9967       0  \n",
      "1              21.1683            6.4457       0  \n",
      "2               9.0741            5.6896       0  \n",
      "3              23.0803            6.0434       0  \n",
      "4               2.8028            4.8451       0  \n",
      "\n",
      "============================================================\n",
      "Data Types:\n",
      "============================================================\n",
      "compound_id             object\n",
      "protein_id              object\n",
      "molecular_weight       float64\n",
      "logp                   float64\n",
      "h_bond_donors            int64\n",
      "h_bond_acceptors         int64\n",
      "rotatable_bonds          int64\n",
      "polar_surface_area     float64\n",
      "compound_clogp         float64\n",
      "protein_length           int64\n",
      "protein_pi             float64\n",
      "hydrophobicity         float64\n",
      "binding_site_size      float64\n",
      "mw_ratio               float64\n",
      "logp_pi_interaction    float64\n",
      "binding_affinity       float64\n",
      "active                   int64\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "Dataset Info Summary:\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   compound_id          2000 non-null   object \n",
      " 1   protein_id           2000 non-null   object \n",
      " 2   molecular_weight     2000 non-null   float64\n",
      " 3   logp                 1940 non-null   float64\n",
      " 4   h_bond_donors        2000 non-null   int64  \n",
      " 5   h_bond_acceptors     2000 non-null   int64  \n",
      " 6   rotatable_bonds      2000 non-null   int64  \n",
      " 7   polar_surface_area   1940 non-null   float64\n",
      " 8   compound_clogp       2000 non-null   float64\n",
      " 9   protein_length       2000 non-null   int64  \n",
      " 10  protein_pi           2000 non-null   float64\n",
      " 11  hydrophobicity       1940 non-null   float64\n",
      " 12  binding_site_size    2000 non-null   float64\n",
      " 13  mw_ratio             2000 non-null   float64\n",
      " 14  logp_pi_interaction  2000 non-null   float64\n",
      " 15  binding_affinity     2000 non-null   float64\n",
      " 16  active               2000 non-null   int64  \n",
      "dtypes: float64(10), int64(5), object(2)\n",
      "memory usage: 265.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 2. Data Loading\n",
    "# ============================\n",
    "\n",
    "# Load the raw dataset\n",
    "dataset_path = os.path.join(DATA_RAW_PATH, \"drug_discovery_virtual_screening.csv\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Loading dataset...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f\"✓ Dataset loaded successfully from: {dataset_path}\")\n",
    "print(f\"\\nDataset shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Data Types:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Dataset Info Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e453b0",
   "metadata": {},
   "source": [
    "## 3. Quality Assessment\n",
    "\n",
    "Before proceeding with any analysis or preprocessing, we need to assess the quality of the raw data.\n",
    "This step identifies issues that must be addressed to ensure model reliability.\n",
    "\n",
    "**We will check for:**\n",
    "- **Missing values**: Identify columns with null/NaN values and their frequency\n",
    "- **Duplicate records**: Detect and count identical rows that may skew analysis\n",
    "- **Target variable inspection**: Examine the distribution and integrity of the activity label (0/1)\n",
    "\n",
    "These quality checks will inform our preprocessing strategy and highlight any data anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a29e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY ASSESSMENT\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "3.1 Missing Values Analysis\n",
      "------------------------------------------------------------\n",
      "Columns with missing values: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logp</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hydrophobicity</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>polar_surface_area</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column  missing_count  missing_pct\n",
       "3                 logp             60       3.0000\n",
       "11      hydrophobicity             60       3.0000\n",
       "7   polar_surface_area             60       3.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved missing values report to: c:\\Users\\KORISNIK\\Documents\\drug-discovery-virtual-screening\\results\\metrics\\00_missing_values_report.csv\n",
      "\n",
      "------------------------------------------------------------\n",
      "3.2 Duplicate Records Analysis\n",
      "------------------------------------------------------------\n",
      "Duplicate rows: 0\n",
      "\n",
      "------------------------------------------------------------\n",
      "3.3 Target Variable (activity) Inspection\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Expected target column 'activity' not found in dataset columns.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m TARGET_COL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TARGET_COL \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected target column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTARGET_COL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in dataset columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m value_counts \u001b[38;5;241m=\u001b[39m df[TARGET_COL]\u001b[38;5;241m.\u001b[39mvalue_counts(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     68\u001b[0m value_pct \u001b[38;5;241m=\u001b[39m df[TARGET_COL]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39msort_index() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Expected target column 'activity' not found in dataset columns.\""
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 3. Quality Assessment\n",
    "# ============================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# -------- 3.1 Missing Values --------\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"3.1 Missing Values Analysis\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "missing_count = df.isna().sum()\n",
    "missing_percent = (df.isna().mean() * 100)\n",
    "\n",
    "missing_report = (\n",
    "    pd.DataFrame({\n",
    "        \"column\": missing_count.index,\n",
    "        \"missing_count\": missing_count.values,\n",
    "        \"missing_pct\": missing_percent.values\n",
    "    })\n",
    "    .sort_values(\"missing_count\", ascending=False)\n",
    ")\n",
    "\n",
    "missing_nonzero = missing_report[missing_report[\"missing_count\"] > 0]\n",
    "\n",
    "if missing_nonzero.empty:\n",
    "    print(\"No missing values detected in any column.\")\n",
    "else:\n",
    "    print(f\"Columns with missing values: {missing_nonzero.shape[0]}\")\n",
    "    display(missing_nonzero)\n",
    "\n",
    "# Save full missingness report\n",
    "missing_path = os.path.join(RESULTS_PATH, \"metrics\", \"00_missing_values_report.csv\")\n",
    "os.makedirs(os.path.dirname(missing_path), exist_ok=True)\n",
    "missing_report.to_csv(missing_path, index=False)\n",
    "print(\"Saved missing values report to:\", missing_path)\n",
    "\n",
    "# -------- 3.2 Duplicate Records --------\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"3.2 Duplicate Records Analysis\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "duplicate_count = int(df.duplicated().sum())\n",
    "\n",
    "print(\"Duplicate rows:\", duplicate_count)\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    duplicate_rows = df[df.duplicated(keep=False)].sort_values(list(df.columns))\n",
    "    display(duplicate_rows.head(10))\n",
    "\n",
    "    dup_path = os.path.join(RESULTS_PATH, \"metrics\", \"00_duplicate_rows_sample.csv\")\n",
    "    duplicate_rows.head(100).to_csv(dup_path, index=False)\n",
    "    print(\"Saved duplicate rows sample to:\", dup_path)\n",
    "\n",
    "# -------- 3.3 Target Variable Inspection --------\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"3.3 Target Variable (activity) Inspection\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "TARGET_COL = \"active\"\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise KeyError(f\"Expected target column '{TARGET_COL}' not found in dataset columns.\")\n",
    "\n",
    "value_counts = df[TARGET_COL].value_counts(dropna=False).sort_index()\n",
    "value_pct = df[TARGET_COL].value_counts(normalize=True, dropna=False).sort_index() * 100\n",
    "\n",
    "target_summary = pd.DataFrame({\n",
    "    \"value\": value_counts.index,\n",
    "    \"count\": value_counts.values,\n",
    "    \"percent\": value_pct.values\n",
    "})\n",
    "\n",
    "display(target_summary)\n",
    "\n",
    "unique_vals = set(df[TARGET_COL].dropna().unique())\n",
    "print(\"Unique target values:\", sorted(unique_vals))\n",
    "print(\"Target dtype:\", df[TARGET_COL].dtype)\n",
    "\n",
    "if not unique_vals.issubset({0, 1}):\n",
    "    print(\"WARNING: Target contains values other than 0 and 1.\")\n",
    "\n",
    "# Target distribution plot (saved)\n",
    "fig_path = os.path.join(RESULTS_PATH, \"figures\", \"00_target_distribution.png\")\n",
    "os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=TARGET_COL, data=df)\n",
    "plt.title(\"Target Distribution: active (0=inactive, 1=active)\")\n",
    "plt.xlabel(\"active\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved target distribution figure to:\", fig_path)\n",
    "\n",
    "# -------- Summary --------\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"QUALITY ASSESSMENT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total rows      : {len(df):,}\")\n",
    "print(f\"Total columns   : {df.shape[1]}\")\n",
    "print(f\"Missing values  : {'None' if missing_nonzero.empty else f'{missing_nonzero.shape[0]} columns affected'}\")\n",
    "print(f\"Duplicate rows  : {duplicate_count}\")\n",
    "print(f\"Memory usage    : {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
